{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LangChain to get structured outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_fireworks import ChatFireworks\n",
    "\n",
    "from experiment_xml import (\n",
    "    pydantic_to_xml_instructions,\n",
    "    run_xml_experiment,\n",
    "    EvalXmlOutput,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTHROPIC_API_KEY = \"<API KEY>\"\n",
    "FIREWORKS_API_KEY = \"<API KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "LANGSMITH_API_KEY = st.secrets[\"api_keys\"][\"LANGSMITH_API_KEY\"]\n",
    "ANTHROPIC_API_KEY = st.secrets[\"api_keys\"][\"ANTHROPIC_API_KEY\"]\n",
    "FIREWORKS_API_KEY = st.secrets[\"api_keys\"][\"FIREWORKS_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_date = \"20-02-25\"\n",
    "n_iter = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a LLM model to run our structured output queries. Use a temperature of 0 to improve structured output generation (but at the cost of \"creativity\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM parameters\n",
    "temperature = 0.8\n",
    "timeout = 30\n",
    "num_ctx = 8192\n",
    "num_predict = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_models_test = {\n",
    "    \"Ollama_llama32\": ChatOllama(\n",
    "        model=\"llama3.2\",\n",
    "        temperature=temperature,\n",
    "        num_ctx=num_ctx,\n",
    "        num_thread=1,\n",
    "        num_predict=num_predict,\n",
    "    ),\n",
    "}\n",
    "llm_models = {\n",
    "    \"Ollama_llama32\": ChatOllama(\n",
    "        model=\"llama3.2\",\n",
    "        temperature=temperature,\n",
    "        num_ctx=num_ctx,\n",
    "        num_thread=1,\n",
    "        num_predict=num_predict,\n",
    "    ),\n",
    "    \"Ollama_nemotron\": ChatOllama(\n",
    "        model=\"nemotron-mini\",\n",
    "        temperature=temperature,\n",
    "        num_ctx=num_ctx,\n",
    "        num_thread=1,\n",
    "        num_predict=num_predict,\n",
    "    ),\n",
    "    \"Ollama_phi3\": ChatOllama(\n",
    "        model=\"phi3\",\n",
    "        temperature=temperature,\n",
    "        num_ctx=num_ctx,\n",
    "        num_thread=1,\n",
    "        num_predict=num_predict,\n",
    "    ),\n",
    "    \"Ollama_phi4\": ChatOllama(\n",
    "        model=\"phi4\",\n",
    "        temperature=temperature,\n",
    "        num_ctx=num_ctx,\n",
    "        num_thread=1,\n",
    "        num_predict=num_predict,\n",
    "    ),\n",
    "    \"Ollama_deepseekr1\": ChatOllama(\n",
    "        model=\"deepseek-r1\",\n",
    "        temperature=temperature,\n",
    "        num_ctx=num_ctx,\n",
    "        num_thread=1,\n",
    "        num_predict=num_predict,\n",
    "    ),\n",
    "    \"fireworks_llama31\": ChatFireworks(\n",
    "        model_name=\"accounts/fireworks/models/llama-v3p1-70b-instruct\",\n",
    "        api_key=FIREWORKS_API_KEY,\n",
    "        temperature=temperature,\n",
    "        timeout=timeout,\n",
    "    ),\n",
    "    \"fireworks_llama32\": ChatFireworks(\n",
    "        model_name=\"accounts/fireworks/models/llama-v3p2-3b-instruct\",\n",
    "        api_key=FIREWORKS_API_KEY,\n",
    "        temperature=temperature,\n",
    "        timeout=timeout,\n",
    "    ),\n",
    "    \"fireworks_llama33\": ChatFireworks(\n",
    "        model_name=\"accounts/fireworks/models/llama-v3p3-70b-instruct\",\n",
    "        api_key=FIREWORKS_API_KEY,\n",
    "        temperature=temperature,\n",
    "        timeout=timeout,\n",
    "    ),\n",
    "    \"fireworks_deepseekr1_70b\": ChatFireworks(\n",
    "        model_name=\"accounts/fireworks/models/deepseek-r1-distill-llama-70b\",\n",
    "        api_key=FIREWORKS_API_KEY,\n",
    "        temperature=temperature,\n",
    "        timeout=timeout,\n",
    "    ),\n",
    "}\n",
    "llm_models_with_anthropic = {\n",
    "    **llm_models,\n",
    "    \"Anthropic_Sonnet_35\": ChatAnthropic(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        api_key=ANTHROPIC_API_KEY,\n",
    "        timeout=timeout,\n",
    "    ),\n",
    "    \"Anthropic_Haiku_35\": ChatAnthropic(\n",
    "        model=\"claude-3-5-haiku-20241022\",\n",
    "        api_key=ANTHROPIC_API_KEY,\n",
    "        timeout=timeout,\n",
    "    ),\n",
    "    \"Anthropic_Haiku_3\": ChatAnthropic(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        api_key=ANTHROPIC_API_KEY,\n",
    "        timeout=timeout,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem setup and prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_science_prompt_txt = \"\"\"\n",
    "You are a professional science writer tasked with responding to members of\n",
    "the general public who write in asking questions about science.\n",
    "Write an article responding to a writer's question for publication in a\n",
    "science magazine intended for a general readership with a high-school education.\n",
    "You should write clearly and compellingly, include all relavent context,\n",
    "and provide motivating stories where applicable.\n",
    "\n",
    "Your response must be less than 200 words.\n",
    "\n",
    "The question given to you is the following:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"What is the oldest recorded fossil?\",\n",
    "    \"What is a black hole?\",\n",
    "    \"How far away is the sun?\",\n",
    "    \"Which other planet in the Solar System has a surface gravity closest to that of the Earth?\",\n",
    "    \"Eris, Haumea, Makemake and Ceres are all examples of what?\",\n",
    "    \"Why does earth have seasons? Do other planets exhibit seasons too?\",\n",
    "    \"What causes the aurora borealis?\",\n",
    "    \"Why is the sky blue?\",\n",
    "    \"How do bees communicate?\",\n",
    "    \"What is the smallest unit of life?\",\n",
    "    \"How do plants make their own food?\",\n",
    "    \"Why do we dream?\",\n",
    "    \"What is the theory of relativity?\",\n",
    "    \"How do volcanoes erupt?\",\n",
    "    \"What is the speed of light?\",\n",
    "    \"How do magnets work?\",\n",
    "    \"What is the purpose of DNA?\",\n",
    "    \"What are the different types of galaxies?\",\n",
    "    \"Why do some animals hibernate?\",\n",
    "    \"How do vaccines work?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_direct = ChatPromptTemplate.from_template(test_science_prompt_txt)\n",
    "\n",
    "prompt_system_format = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Return a publishable article in the requested format.\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", test_science_prompt_txt),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_user_format = ChatPromptTemplate.from_template(\n",
    "    test_science_prompt_txt + \"\\n{format_instructions}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schema using Pydantic XML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_xml import BaseXmlModel, element, attr\n",
    "\n",
    "\n",
    "class ArticleResponse1XML(BaseXmlModel, tag=\"article\"):\n",
    "    \"\"\"Structured article for publication answering a reader's question.\"\"\"\n",
    "\n",
    "    title: str = element(description=\"Title of the article\")\n",
    "    answer: str = element(\n",
    "        description=\"Provide a detailed description of historical events to answer the question\"\n",
    "    )\n",
    "    number: int = element(description=\"A number that is most relevant to the question.\")\n",
    "\n",
    "\n",
    "# Lists of simple types\n",
    "class ArticleResponse2XML(BaseXmlModel, tag=\"article\"):\n",
    "    \"\"\"Structured article for publication answering a reader's question.\"\"\"\n",
    "\n",
    "    title: str = element(description=\"Title of the article\")\n",
    "    answer: str = element(description=\"Answer the writer's question\")\n",
    "    further_questions: list[str] = element(\n",
    "        tag=\"further_question\",\n",
    "        description=\"A list of related questions that may be of interest to the readers.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Nested types\n",
    "class HistoricalEventXML(BaseXmlModel):\n",
    "    \"\"\"The year and explanation of a historical event.\"\"\"\n",
    "\n",
    "    year: str = element(description=\"The year of the historical event\")\n",
    "    event: str = element(\n",
    "        description=\"A clear and concise explanation of what happened in this event\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ArticleResponse3XML(BaseXmlModel, tag=\"article\"):\n",
    "    \"\"\"Structured article for publication answering a reader's question.\"\"\"\n",
    "\n",
    "    title: str = element(description=\"[Title of the article]\")\n",
    "    historical_event_1: HistoricalEventXML = element(\n",
    "        description=\"A first historical event relevant to the question\"\n",
    "    )\n",
    "    historical_event_2: HistoricalEventXML = element(\n",
    "        description=\"A second historical event relevant to the question\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Lists of custom types\n",
    "class ArticleResponse4XML(BaseXmlModel, tag=\"article\"):\n",
    "    \"\"\"Structured article for publication answering a reader's question.\"\"\"\n",
    "\n",
    "    title: str = element(description=\"Title of the article\")\n",
    "    historical_timeline: list[HistoricalEventXML] = element(\n",
    "        description=\"A list of historical events relevant to the question\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_formats_xml = [\n",
    "    dict(pydantic=schema, format_instructions=pydantic_to_xml_instructions(schema))\n",
    "    for schema in [\n",
    "        ArticleResponse1XML,\n",
    "        ArticleResponse2XML,\n",
    "        ArticleResponse3XML,\n",
    "        ArticleResponse4XML,\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ollama_llama32  Output: ArticleResponse1XML   Pos: 0\n",
      "Error: ValidationError\n",
      "..Error: ValidationError\n",
      ".Error: ValidationError\n",
      "....Error: ValidationError\n",
      "..Error: ValidationError\n",
      ".Error: ValidationError\n",
      ".Error: ValidationError\n",
      ".Error: ValidationError\n",
      ".Error: ValidationError\n",
      ".Error: ValidationError\n",
      "..Error: ValidationError\n",
      ".Error: ValidationError\n",
      ".Error: ValidationError\n",
      ".Error: ValidationError\n",
      ".\n",
      "Model: Ollama_llama32  Output: ArticleResponse2XML   Pos: 1\n",
      "....................\n",
      "Model: Ollama_llama32  Output: ArticleResponse3XML   Pos: 2\n",
      "....Error: RuntimeError\n",
      "...Error: RuntimeError\n",
      "..Error: ValidationError\n",
      "........Error: RuntimeError\n",
      "...\n",
      "Model: Ollama_llama32  Output: ArticleResponse4XML   Pos: 3\n",
      "Error: RuntimeError\n",
      "..Error: XMLSyntaxError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: RuntimeError\n",
      ".....Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      "..Error: XMLSyntaxError\n",
      ".Error: RuntimeError\n",
      "...Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      "..\n",
      "Model: Ollama_nemotron  Output: ArticleResponse1XML   Pos: 4\n",
      "Error: RuntimeError\n",
      "..Error: RuntimeError\n",
      "....Error: ValidationError\n",
      ".Error: RuntimeError\n",
      ".Error: ValidationError\n",
      ".Error: RuntimeError\n",
      "..Error: RuntimeError\n",
      "..Error: RuntimeError\n",
      ".Error: ValidationError\n",
      "......\n",
      "Model: Ollama_nemotron  Output: ArticleResponse2XML   Pos: 5\n",
      "Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: ValidationError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".\n",
      "Model: Ollama_nemotron  Output: ArticleResponse3XML   Pos: 6\n",
      "Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: ValidationError\n",
      ".Error: RuntimeError\n",
      "..Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".\n",
      "Model: Ollama_nemotron  Output: ArticleResponse4XML   Pos: 7\n",
      "Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      "..Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      "..Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".\n",
      "Model: Ollama_phi3  Output: ArticleResponse1XML   Pos: 8\n",
      "Error: ValidationError\n",
      "..Error: ValidationError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: XMLSyntaxError\n",
      "...Error: RuntimeError\n",
      "..Error: ValidationError\n",
      "..Error: XMLSyntaxError\n",
      "..Error: RuntimeError\n",
      ".Error: XMLSyntaxError\n",
      "...Error: RuntimeError\n",
      "...\n",
      "Model: Ollama_phi3  Output: ArticleResponse2XML   Pos: 9\n",
      "Error: XMLSyntaxError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: RuntimeError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: ValidationError\n",
      ".Error: RuntimeError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: XMLSyntaxError\n",
      ".\n",
      "Model: Ollama_phi3  Output: ArticleResponse3XML   Pos: 10\n",
      "Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: ValidationError\n",
      ".Error: RuntimeError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: RuntimeError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: RuntimeError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: RuntimeError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: ValidationError\n",
      ".Error: XMLSyntaxError\n",
      ".\n",
      "Model: Ollama_phi3  Output: ArticleResponse4XML   Pos: 11\n",
      "Error: ValidationError\n",
      ".Error: RuntimeError\n",
      ".Error: XMLSyntaxError\n",
      ".Error: ValidationError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      "..Error: XMLSyntaxError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: ValidationError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".Error: RuntimeError\n",
      ".\n",
      "Model: Ollama_phi4  Output: ArticleResponse1XML   Pos: 12\n",
      "Error: ValidationError\n",
      "...Error: ValidationError\n",
      "."
     ]
    }
   ],
   "source": [
    "if \"structure_support_by_model_sp\" not in locals():\n",
    "    structure_support_by_model_sp = {}\n",
    "\n",
    "run_xml_experiment(\n",
    "    prompt_system_format,\n",
    "    questions,\n",
    "    llm_models,\n",
    "    structured_formats_xml,\n",
    "    n_iter=1,\n",
    "    results_out=structure_support_by_model_sp,\n",
    "    save_file_name=f\"exp5_xml_output_sp_{experiment_date}.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all error messages & count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_df(ss_results, key=\"valid\"):\n",
    "    df = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            mname: {\n",
    "                tname: ss_results[mname][tname][key] * 100 / n_questions\n",
    "                for tname in ss_results[mname].keys()\n",
    "            }\n",
    "            for mname in ss_results.keys()\n",
    "        },\n",
    "        orient=\"index\",\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def analyse_errors_from_results(ss_results, method=\"code\"):\n",
    "    error_counts = {}\n",
    "    for mname in ss_results.keys():\n",
    "        error_counts[mname] = {}\n",
    "        for tname in ss_results[mname].keys():\n",
    "            validation_error = 0\n",
    "            json_error = 0\n",
    "            unknown_error = 0\n",
    "\n",
    "            # Count errors by failure code above\n",
    "            if method == \"code\":\n",
    "                error_types = pd.Series(\n",
    "                    output[\"error_type\"]\n",
    "                    for output in ss_results[mname][tname][\"outputs\"]\n",
    "                )\n",
    "                error_codes = error_types.value_counts()\n",
    "\n",
    "                for e_name, e_count in error_codes.items():\n",
    "                    error_counts[mname][(tname, e_name)] = e_count\n",
    "\n",
    "            elif method == \"parse\":\n",
    "                # Count errors by parsing error message\n",
    "                errors = (\n",
    "                    output[\"error_message\"]\n",
    "                    for output in ss_results[mname][tname][\"outputs\"]\n",
    "                )\n",
    "                for error in errors:\n",
    "                    if error is None:\n",
    "                        continue\n",
    "                    if error.lower().find(\"opening and ending tag mismatch\") >= 0:\n",
    "                        error_str = \"XML tag mismatch\"\n",
    "                    elif error.lower().find(\"input should be a valid integer\") >= 0:\n",
    "                        error_str = \"Validation error (int)\"\n",
    "                    elif error.lower().find(\"premature end of data in tag\") >= 0:\n",
    "                        error_str = \"Premature end\"\n",
    "                    elif error.lower().find(\"field required\") >= 0:\n",
    "                        error_str = \"Missing field\"\n",
    "                    elif error.lower().find(\"expected '>'\") >= 0:\n",
    "                        error_str = \"Tag malformed\"\n",
    "                    elif (\n",
    "                        error.lower().find(\"extra content at the end of the document\")\n",
    "                        >= 0\n",
    "                    ):\n",
    "                        error_str = \"Tag malformed\"\n",
    "                    else:\n",
    "                        error_str = error\n",
    "\n",
    "                    error_counts[mname][(tname, error_str)] = (\n",
    "                        error_counts[mname].get((tname, error_str), 0) + 1\n",
    "                    )\n",
    "\n",
    "            else:\n",
    "                raise NameError(f\"Method {method} not supported\")\n",
    "\n",
    "    return pd.DataFrame.from_dict(error_counts, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ArticleResponse1XML</th>\n",
       "      <th>ArticleResponse2XML</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ArticleResponse3XML</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ArticleResponse4XML</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Validation error (int)</th>\n",
       "      <th>Tag malformed</th>\n",
       "      <th>Premature end</th>\n",
       "      <th>Missing field</th>\n",
       "      <th>Tag malformed</th>\n",
       "      <th>Premature end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ollama_llama32</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ArticleResponse1XML ArticleResponse2XML ArticleResponse3XML  \\\n",
       "               Validation error (int)       Tag malformed       Premature end   \n",
       "Ollama_llama32                     16                   1                   5   \n",
       "\n",
       "                             ArticleResponse4XML                \n",
       "               Missing field       Tag malformed Premature end  \n",
       "Ollama_llama32             2                   7             2  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_errors_from_results(structure_support_by_model, method=\"parse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in structure_support_by_model[\"Ollama_llama32\"][\"ArticleResponse4XML\"][\n",
    "    \"outputs\"\n",
    "]:\n",
    "    if output[\"error_type\"] != \"ok\":\n",
    "        print(output[\"error_message\"], \"\\n\")\n",
    "        print(output[\"raw\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Standard Prompt'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_list = {\n",
    "    \"Standard Prompt\": structure_support_by_model,\n",
    "}\n",
    "\n",
    "df_results = {}\n",
    "for name, ss_results in results_list.items():\n",
    "    df_results[name] = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            mname: {\n",
    "                tname: ss_results[mname][tname][\"valid\"] * 100\n",
    "                for tname in ss_results[mname].keys()\n",
    "            }\n",
    "            for mname in ss_results.keys()\n",
    "        },\n",
    "        orient=\"index\",\n",
    "    )\n",
    "    display(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ArticleResponse1XML</th>\n",
       "      <th>ArticleResponse2XML</th>\n",
       "      <th>ArticleResponse3XML</th>\n",
       "      <th>ArticleResponse4XML</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ollama_llama32</th>\n",
       "      <th>Standard Prompt</th>\n",
       "      <td>20.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ArticleResponse1XML  ArticleResponse2XML  \\\n",
       "Ollama_llama32 Standard Prompt                 20.0                 95.0   \n",
       "\n",
       "                                ArticleResponse3XML  ArticleResponse4XML  \n",
       "Ollama_llama32 Standard Prompt                 65.0                 55.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(df_results).swaplevel(axis=0).sort_index(axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
